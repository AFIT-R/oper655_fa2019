---
title: "OPER 655 Student Project Report"
author: "Capt Brandon Hufstetler"
date: "`r format(Sys.Date(), '%d %b %Y')`"
output: 
  html_document:
    code_folding: 'hide'
abstract: 'This file walks a user through an implementation of the Huf Pipeline using transcripts from The Office.'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = F,
                      warning = F, 
                      comment = NA)
```

# Overview
This pipeline implementation will walk a user through the text mining processes of:

1. Downloading, cleaning, and saving television show transcripts from *https://www.springfieldspringfield.co.uk/*
2. Importing these text files into a corpus
3. Tokenizing items from the corpus into a tibble for use with **tidy** package
4. Casting the tibble into a Document Frequency Matrix object for use with **quanteda** package, a Document Term Matrix object for use with **tm** package, a Term Document Matrix object for use with **tm** package, or a sparse matrix
5. Visualizing text statistics
6. Visualizing word counts and frequencies from tibble
7. Visualizing term-frequency inverse-document frequency from tibble
 


## Initialization
First, the locations where we want to store the transcripts 

```{r}
proj_root   <- rprojroot::find_root(rprojroot::is_rstudio_project)
save_folder <- base::file.path(proj_root,'student_project_folders','oper655_fa2019_hufstetler','Data')
url_root <- 'https://www.springfieldspringfield.co.uk/'
url  <- 'https://www.springfieldspringfield.co.uk/episode_scripts.php?tv-show=the-office-us'
```

